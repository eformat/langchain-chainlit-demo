---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: chatbot
    app.kubernetes.io/component: chatbot
    app.kubernetes.io/instance: chatbot
  name: chatbot
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      deployment: chatbot
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        openshift.io/generated-by: OpenShiftNewApp
      creationTimestamp: null
      labels:
        deployment: chatbot
    spec:
      containers:
      - env:
        - name: INFERENCE_SERVER_URL
          value: https://sno-llama31-cpp-predictor-llama-serving.apps.sno.sandbox1771.opentlc.com/v1
        - name: DB_CONNECTION_STRING
          value: postgresql+psycopg://postgres:password@postgres:5432/vectordb
        image: image-registry.openshift-image-registry.svc:5000/openshift/chatbot:latest
        imagePullPolicy: IfNotPresent
        name: chatbot
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
